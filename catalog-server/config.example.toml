# Pezzottify Catalog Server Configuration
# Copy this file to config.toml and customize for your deployment.
# Values here override CLI arguments.

# Core settings
db_dir = "/data/db"
media_path = "/data/media"
port = 3001
metrics_port = 9091
logging_level = "path"
content_cache_age_sec = 60
frontend_dir_path = "/app/web"

# Downloader service URL (enables download manager when set)
# The downloader should be on the same Docker network (pezzottify-internal)
# downloader_url = "http://downloader:3002"
downloader_timeout_sec = 300

# Event pruning
event_retention_days = 30
prune_interval_hours = 24

# Download Manager settings
# Enables passive download queue. Users submit requests, an external script
# picks them up and fulfills them via the ingestion system.
[download_manager]

# Rate Limiting
# Maximum albums a user can request per hour
max_albums_per_hour = 10
# Maximum albums a user can request per day
max_albums_per_day = 60
# Maximum requests a user can make per day (across all types)
user_max_requests_per_day = 100
# Maximum items a user can have in the queue at once
user_max_queue_size = 200

# Time before in-progress items are flagged as stale (seconds)
stale_in_progress_threshold_secs = 3600

# Retry Settings
# Maximum retry attempts for failed downloads
max_retries = 8
# Initial delay before first retry (seconds)
initial_backoff_secs = 60
# Maximum delay between retries (seconds)
max_backoff_secs = 86400
# Multiplier for exponential backoff
backoff_multiplier = 2.5

# Audit Log
# Days to retain audit log entries (0 to disable cleanup)
audit_log_retention_days = 90

# Search settings
[search]
# Search engine to use: "pezzothash" (default), "fts5", "fts5-levenshtein", "noop"
# - pezzothash: SimHash-based fuzzy search (built-in typo tolerance, unbounded memory)
# - fts5: SQLite FTS5 with trigram tokenizer (fast, bounded memory)
# - fts5-levenshtein: FTS5 with Levenshtein-based typo correction (best typo tolerance)
# - noop: Disabled search (returns empty results, fastest startup)
engine = "pezzothash"

# Catalog Store settings
[catalog_store]
# Number of connections for concurrent read operations (default: 4)
# Increase this value if you have high concurrent read traffic
# Each connection uses additional memory, so don't over-provision
read_pool_size = 4

# Background Jobs settings
[background_jobs]
# Future: per-job configuration
